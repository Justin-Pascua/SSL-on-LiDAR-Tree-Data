import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix

import torch
import numpy as np

species_strings = ['Norway Spruce', 'European Larch', 'Other broadleaves', 
                   'Silver fir', 'Broadleaves', 'Green alder', 
                   'Pines', 'Scots Pine']

def one_hot_decode(y):
    """
    Decodes one-hot encoded vector
    params:
        y: a one-hot encoded vector
    """
    return y.argmax()

def get_confusion_matrix(model, labeled_dataloader, normalize = 'true'):
    """
    Applies the model to the dataset associated the labeled_dataloader in order to
    generate predictions and compute a confusion matrix. Normalizes matrix if indicated
    params:
        model: a PyTorch model compatible with the LiDAR Tree data
        
        labeled_dataloader: a PyTorch DataLoader associated with a dataset of labeled tree samples
        
        normalize: a string (either 'true', 'pred', or 'all') or None. 
        If normalize == 'true', then confusion matrix is normalized along rows.
        If normalize == 'pred', then confusion matrix is normalized along columns.
        If normalize == 'all', then confusion matrix is normalized over all entries.
        If normalize == None, then confusion matrix is not normalized.
    """
    y_true, y_pred = [], []
    with torch.no_grad():
        for x,y in labeled_dataloader:
            preds = model(x).argmax(1)
            y_true.extend(y.argmax(1).cpu().numpy())
            y_pred.extend(preds.cpu().numpy())

    cm = confusion_matrix(y_true, y_pred, normalize = normalize)
    return cm

def plot_confusion_matrix(model, labeled_dataloader, normalize = 'true'):
    """
    Plots the confusion matrix generated by get_confusion_matrix using seaborn.
    params:
        model: a PyTorch model compatible with the LiDAR Tree data
        
        labeled_dataloader: a PyTorch DataLoader associated with a dataset of labeled tree samples
        
        normalize: a string (either 'true', 'pred', or 'all') or None. 
        If normalize == 'true', then confusion matrix is normalized along rows.
        If normalize == 'pred', then confusion matrix is normalized along columns.
        If normalize == 'all', then confusion matrix is normalized over all entries.
        If normalize == None, then confusion matrix is not normalized.
    """
    cm = get_confusion_matrix(model, labeled_dataloader, normalize = normalize)
    plt.figure(figsize=(10, 8))
    sns.heatmap(cm, annot=True, cmap = plt.cm.Oranges,
                xticklabels = species_strings,
                yticklabels = species_strings)
    plt.xlabel("Predicted")
    plt.ylabel("True")
    plt.title(f"Confusion Matrix Normalized By '{normalize}'")
    plt.show()
  
def get_f1_scores(model, labeled_dataloader):
    """
    Applies the model to the dataset associated the labeled_dataloader and computes 
    F1 scores for each class. Returns the F1 scores as a 1D numpy array ordered by
    class labels (i.e. the 0'th entry is the F1-score for class 0).
    params:
        model: a PyTorch model compatible with the LiDAR Tree data
        
        labeled_dataloader: a PyTorch DataLoader associated with a dataset of labeled tree samples
    """
    cm = get_confusion_matrix(model, labeled_dataloader, normalize = None)
    n_classes = cm.shape[0]
    f1_scores = []

    for i in range(n_classes):
        # True Positives (TP)
        tp = cm[i, i]
        
        # False Positives (FP) = Sum of column i (excluding TP)
        fp = np.sum(cm[:, i]) - tp
        
        # False Negatives (FN) = Sum of row i (excluding TP)
        fn = np.sum(cm[i, :]) - tp
        
        # Precision and Recall
        precision = tp / (tp + fp) if (tp + fp) > 0 else 0
        recall = tp / (tp + fn) if (tp + fn) > 0 else 0
        
        # F1 Score
        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0
        f1_scores.append(f1)

    return np.array(f1_scores)

def print_f1_scores(model, labeled_dataloader):
    """
    Prints the F1 scores generated by get_f1_scores, as well as the macro-F1 score
    params:
        model: a PyTorch model compatible with the LiDAR Tree data
        
        labeled_dataloader: a PyTorch DataLoader associated with a dataset of labeled tree samples
    """
    f1_scores = get_f1_scores(model, labeled_dataloader)
    for i, species in enumerate(species_strings):
        print(f"{species}: {f1_scores[i]: .3f}")
    print(f"Macro F1 Score: {np.mean(f1_scores): .3f}")
  
    
def plot_f1_scores(model, labeled_dataloader):
    """
    Plots the F1 scores generated by get_f1_scores as a bar plot. 
    Plots the macro-F1 score as a dashed vertical line.
    params:
        model: a PyTorch model compatible with the LiDAR Tree data
        
        labeled_dataloader: a PyTorch DataLoader associated with a dataset of labeled tree samples
    """
    raw_f1_scores = get_f1_scores(model, labeled_dataloader)
    macro_f1 = np.mean(raw_f1_scores)
    variance = np.var(raw_f1_scores)
    
    plt.bar(species_strings, raw_f1_scores, label = f'Variance = {variance: .3f}')
    plt.axhline(y = macro_f1, color='r', linestyle='--', label = f'Macro-F1 = {macro_f1: .3f}')
    plt.xticks(rotation = 45)
    plt.ylabel('F1 Score')
    plt.legend()
    plt.show()
    